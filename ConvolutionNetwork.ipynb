{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ConvolutionNetwork.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOQPBikTrVd04u28raTj+Ex",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minhvvan/DeepLearning/blob/main/ConvolutionNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUNHEfyW9tSZ",
        "outputId": "9cd227be-a670-480d-af21-8d385703242a"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "from sklearn.datasets import load_breast_cancer\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "cancer = load_breast_cancer()\r\n",
        "x = cancer.data\r\n",
        "y = cancer.target\r\n",
        "x_train_all, x_test, y_train_all, y_test = train_test_split(x, y, stratify = y, test_size=0.2, random_state=42)\r\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, stratify = y_train_all, test_size=0.2, random_state=42)\r\n",
        "\r\n",
        "print(x_train.shape, x_val.shape)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(364, 30) (91, 30)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rkNgBTeR_juJ"
      },
      "source": [
        "class SingleLayer:\r\n",
        "\r\n",
        "  def __init__(self, learning_rate=0.1, l1=2, l2=0):\r\n",
        "    self.w = None\r\n",
        "    self.b = None\r\n",
        "    self.losses = []\r\n",
        "    self.val_losses = []\r\n",
        "    self.w_history = []\r\n",
        "    self.lr = learning_rate\r\n",
        "    self.l1 = l1\r\n",
        "    self.l2 = l2\r\n",
        "\r\n",
        "  def forpass(self,x):\r\n",
        "    z = np.dot(x, self.w) + self.b\r\n",
        "    return z\r\n",
        "\r\n",
        "  def backprop(self, x, err):\r\n",
        "    m = len(x)\r\n",
        "    w_grad = np.dot(x.T, err) / m   #가중치에 대한 평균 그레이디언트 계산\r\n",
        "    b_grad = np.sum(err) / m    #절편에 대한 평균 그레이디언트 계산\r\n",
        "    return w_grad, b_grad\r\n",
        "\r\n",
        "  def activation(self, z):\r\n",
        "    a = 1 / (1 + np.exp(-z))\r\n",
        "    return a\r\n",
        "\r\n",
        "  def fit(self, x, y, epochs=100, x_val=None, y_val=None):\r\n",
        "    y = y.reshape(-1,1) #타겟을 열벡터로 변환\r\n",
        "    y_val = y_val.reshape(-1,1) #val타겟을 열벡터로 변환\r\n",
        "    m = len(x)\r\n",
        "    self.w = np.ones((x.shape[1],1))  #가중치 초기화\r\n",
        "    self.b = 0\r\n",
        "    self.w_history.append(self.w.copy())  #가중치 기록\r\n",
        "\r\n",
        "    for i in range(epochs):\r\n",
        "      z = self.forpass(x) #정방향 계산\r\n",
        "      a = self.activation(z) #활성화 함수\r\n",
        "      err = -(y - a)\r\n",
        "      w_grad, b_grad = self.backprop(x,err)  #역방향 계산\r\n",
        "      w_grad += (self.l1 * np.sign(self.w) + self.l2 * self.w) / m  #그레이디언트 패널티적용\r\n",
        "      self.w -= self.lr * w_grad  #가중치 업데이트\r\n",
        "      self.b -= self.lr * b_grad  #절편 업데이트\r\n",
        "      self.w_history.append(self.w.copy()) #가중치 기록\r\n",
        "      a = np.clip(a, 1e-10,1-1e-10) #클리핑\r\n",
        "      loss = np.sum(-(y*np.log(a) + (1-y)*np.log(1-a))) #로그 손실과 규제 손실 적용\r\n",
        "      self.losses.append((loss + self.reg_loss()) / m)\r\n",
        "      self.update_val_loss(x_val, y_val)  #검증\r\n",
        "\r\n",
        "  \r\n",
        "  def predict(self, x):\r\n",
        "    z = self.forpass(x)\r\n",
        "    return z > 0\r\n",
        "\r\n",
        "  def update_val_loss(self, x_val, y_val):\r\n",
        "    z = self.forpass(x_val)\r\n",
        "    a = self.activation(z)\r\n",
        "    a = np.clip(a, 1e-10,1-1e-10) #클리핑\r\n",
        "    val_loss = np.sum(-(y_val*np.log(a) + (1-y_val)*np.log(1-a)))\r\n",
        "    self.val_losses.append((val_loss + self.reg_loss()) / len(y_val))\r\n",
        "\r\n",
        "  def score(self, x, y):\r\n",
        "    return np.mean(self.predict(x) == y.reshape(-1,1))\r\n",
        "\r\n",
        "  def reg_loss(self):\r\n",
        "    return self.l1 * np.sum(np.abs(self.w)) + self.l2 / 2 * np.sum(self.w**2)\r\n",
        "  \r\n",
        "  def update_val_loss(self, x_val, y_val):\r\n",
        "    z = self.forpass(x_val)   #정방향 계산\r\n",
        "    a = self.activation(z)  #활성화 함수\r\n",
        "    a = np.clip(a, 1e-10,1-1e-10) #클리핑\r\n",
        "    val_loss = np.sum(-(y_val*np.log(a) + (1-y_val)*np.log(1-a)))\r\n",
        "    self.val_losses.append((val_loss + self.reg_loss()) / len(y_val)) #로그 손실, 규제 손실 더하여 기록\r\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IX_qkL5grdNq"
      },
      "source": [
        "class DualLayer(SingleLayer):\r\n",
        "\r\n",
        "  def __init__(self, units=10, learning_rate=0.1, l1=0, l2=0):\r\n",
        "    self.units = units  #은닉층 뉴런 개수\r\n",
        "    self.w1 = None  #은닉층 가중치\r\n",
        "    self.b1 = None  #은닉층 절편\r\n",
        "    self.w2 = None  #출력층 가중치\r\n",
        "    self.b2 = None  #출력층 절편\r\n",
        "    self.a1 = None  #은닉층 활성화 출력\r\n",
        "    self.losses = []  #훈련 손실\r\n",
        "    self.val_losses = []  #검승 손실\r\n",
        "    self.lr = learning_rate #학습률\r\n",
        "    self.l1 = l1  #l1 규제\r\n",
        "    self.l2 = l2  #l2 규제\r\n",
        "\r\n",
        "  def forpass(self, x):\r\n",
        "    z1 = np.dot(x, self.w1) + self.b1 #첫 번쨰 층 선형식 계산\r\n",
        "    self.a1 = self.activation(z1) #활성화 함수\r\n",
        "    z2 = np.dot(self.a1, self.w2) + self.b2 #두번째 선형식 계산\r\n",
        "\r\n",
        "    return z2\r\n",
        "\r\n",
        "  def backprop(self, x, err):\r\n",
        "    m = len(x)  #샘플 개수\r\n",
        "    w2_grad = np.dot(self.a1.T, err) / m  #출력층 그레이디언트\r\n",
        "    b2_grad = np.sum(err) / m\r\n",
        "    err_to_hidden = np.dot(err, self.w2.T) * self.a1 * (1 - self.a1)  #시그모이드 그레이디언트 계산\r\n",
        "    w1_grad = np.dot(x.T, err_to_hidden) / m  #은닉층 그레이디언트\r\n",
        "    b1_grad = np.sum(err_to_hidden) / m\r\n",
        "    return w1_grad, b1_grad, w2_grad, b2_grad\r\n",
        "\r\n",
        "  def init_weights(self, n_featuers):\r\n",
        "    self.w1 = np.ones((n_featuers, self.units)) #(특성 개수, 은닉층 크기)\r\n",
        "    self.b1 = np.zeros(self.units)  #은닉층 크기\r\n",
        "    self.w2 = np.ones((self.units, 1)) #(은닉층 크기,1)\r\n",
        "    self.b2 = 0\r\n",
        "\r\n",
        "  def fit(self, x, y, epochs=100, x_val=None, y_val=None):\r\n",
        "    y = y.reshape(-1, 1)\r\n",
        "    y_val = y_val.reshape(-1, 1)\r\n",
        "    m = len(x)\r\n",
        "    self.init_weights(x.shape[1]) #가중치 초기화\r\n",
        "    for i in range(epochs):\r\n",
        "      a = self.training(x, y, m)\r\n",
        "      a = np.clip(a, 1e-10,1-1e-10) #클리핑\r\n",
        "      loss = np.sum(-(y*np.log(a) + (1-y)*np.log(1-a))) #로그 손실 추가\r\n",
        "      self.losses.append((loss + self.reg_loss()) / m)\r\n",
        "      self.update_val_loss(x_val, y_val)\r\n",
        "\r\n",
        "  def training(self, x, y, m):\r\n",
        "    z = self.forpass(x) #정방향 계산\r\n",
        "    a = self.activation(z)  #활성화 함수\r\n",
        "    err = -(y - a)  #오차 계산\r\n",
        "    w1_grad, b1_grad, w2_grad, b2_grad = self.backprop(x, err)\r\n",
        "    #그레이디언트 규제\r\n",
        "    w1_grad += (self.l1 * np.sign(self.w1) + self.l2 * self.w1) / m\r\n",
        "    w2_grad += (self.l1 * np.sign(self.w2) + self.l2 * self.w2) / m\r\n",
        "    #은닉층 가중치 절편 업데이트\r\n",
        "    self.w1 -= self.lr * w1_grad\r\n",
        "    self.b1 -= self.lr * b1_grad\r\n",
        "    #출력층 가중치 절편 업데이트\r\n",
        "    self.w2 -= self.lr * w2_grad\r\n",
        "    self.b2 -= self.lr * b2_grad\r\n",
        "\r\n",
        "    return a\r\n",
        "\r\n",
        "  def reg_loss(self):\r\n",
        "    #은닉층과 출력층의 가중치에 규제 적용\r\n",
        "    return self.l1 * (np.sum(np.abs(self.w1)) + np.sum(np.abs(self.w2))) + self.l2 / 2 * (np.sum(self.w1**2) + np.sum(self.w2**2))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOFTQxj1zs8_"
      },
      "source": [
        "class RandomInitNetwork(DualLayer):\r\n",
        "  def init_weights(self, n_featuers):\r\n",
        "    np.random.seed(42)\r\n",
        "    self.w1 = np.random.normal(0, 1, (n_featuers,self.units))  #(특성 개수, 은닉층 크기)\r\n",
        "    self.b1 = np.zeros(self.units)  #은닉층 크기\r\n",
        "    self.w2 = np.random.normal(0, 1, (self.units, 1))  #(은닉층 크기, 1)\r\n",
        "    self.b2 = 0"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HP119PGTGXrv"
      },
      "source": [
        "class MinibatchNetwork(RandomInitNetwork):\r\n",
        "\r\n",
        "  def __init__(self, units=10, batch_size=32, learning_rate=0.1, l1=0, l2=0):\r\n",
        "    super().__init__(units, learning_rate, l1, l2)\r\n",
        "    self.batch_size = batch_size  #배치 크기\r\n",
        "\r\n",
        "  def fit(self, x, y, epochs=100, x_val=None, y_val=None):\r\n",
        "    y_val = y_val.reshape(-1,1) #타깃 열 벡터로 변환\r\n",
        "    self.init_weights(x.shape[1]) #은닉층과 출력층 가중치 초기화\r\n",
        "    np.random.seed(42)\r\n",
        "    for i in range(epochs):\r\n",
        "      loss = 0\r\n",
        "      for x_batch, y_batch in self.gen_batch(x, y):\r\n",
        "        y_batch = y_batch.reshape(-1, 1)  #타깃 열 벡터로 변환\r\n",
        "        m = len(x_batch)\r\n",
        "        a = self.training(x_batch, y_batch, m)\r\n",
        "        a = np.clip(a, 1e-10,1-1e-10) #클리핑\r\n",
        "        loss += np.sum(-(y_batch*np.log(a) + (1-y_batch)*np.log(1-a)))\r\n",
        "      self.losses.append((loss + self.reg_loss()) / len(x))\r\n",
        "      self.update_val_loss(x_val, y_val)  #검증 손실 계산\r\n",
        "\r\n",
        "  def gen_batch(self, x, y):\r\n",
        "    length = len(x)\r\n",
        "    bins = length // self.batch_size  #미니 배치 횟수\r\n",
        "    if length % self.batch_size:  #나누어 떨어지지 않으면 1추가\r\n",
        "      bins += 1\r\n",
        "    indexes = np.random.permutation(np.arange(len(x)))  #인덱스 셔플\r\n",
        "    x = x[indexes]\r\n",
        "    y = y[indexes]\r\n",
        "    for i in range(bins):\r\n",
        "      start = self.batch_size * i\r\n",
        "      end = self.batch_size * (i + 1)\r\n",
        "      yield x[start:end], y[start:end]  #batch_size만큼 슬라이싱하여 반환"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4thZu8U_NsuR"
      },
      "source": [
        "class MultiClassNetwork(MinibatchNetwork):\r\n",
        "\r\n",
        "  def sigmoid(self, z):\r\n",
        "    a = 1 / (1 + np.exp(-z))  #시그모이드 계산\r\n",
        "    return a\r\n",
        "\r\n",
        "  def softmax(self, z):\r\n",
        "    #소프트맥스 함수\r\n",
        "    exp_z = np.exp(z)\r\n",
        "    return exp_z / np.sum(exp_z, axis=1).reshape(-1,1)\r\n",
        "\r\n",
        "  def forpass(self, x):\r\n",
        "    z1 = np.dot(x, self.w1) + self.b1 #첫 번쨰 층 선형식 계산\r\n",
        "    self.a1 = self.sigmoid(z1) #활성화 함수\r\n",
        "    z2 = np.dot(self.a1, self.w2) + self.b2 #두번째 선형식 계산\r\n",
        "\r\n",
        "    return z2\r\n",
        "\r\n",
        "  def init_weights(self, n_featuers, n_classes):\r\n",
        "    np.random.seed(42)\r\n",
        "    self.w1 = np.random.normal(0, 1, (n_featuers,self.units))  #(특성 개수, 은닉층 크기)\r\n",
        "    self.b1 = np.zeros(self.units)  #은닉층 크기\r\n",
        "    self.w2 = np.random.normal(0, 1, (self.units, n_classes))  #(은닉층 크기, 클래스 개수)\r\n",
        "    self.b2 = np.zeros(n_classes)\r\n",
        "\r\n",
        "  def fit(self, x, y, epochs=100, x_val=None, y_val=None):\r\n",
        "    self.init_weights(x.shape[1], y.shape[1]) #은닉층과 출력층 가중치 초기화\r\n",
        "    np.random.seed(42)\r\n",
        "    for i in range(epochs):\r\n",
        "      loss = 0\r\n",
        "      print('.', end='')\r\n",
        "      for x_batch, y_batch in self.gen_batch(x, y):\r\n",
        "        a = self.training(x_batch, y_batch)\r\n",
        "        a = np.clip(a, 1e-10,1-1e-10) #클리핑\r\n",
        "        loss += np.sum(-y_batch*np.log(a))\r\n",
        "      self.losses.append((loss + self.reg_loss()) / len(x))\r\n",
        "      self.update_val_loss(x_val, y_val)  #검증 손실 계산\r\n",
        "\r\n",
        "  def training(self, x, y):\r\n",
        "    m = len(x)  #샘플 개수\r\n",
        "    z = self.forpass(x) #정방향 계산\r\n",
        "    a = self.sigmoid(z)  #활성화 함수\r\n",
        "    err = -(y - a)  #오차 계산\r\n",
        "    w1_grad, b1_grad, w2_grad, b2_grad = self.backprop(x, err)\r\n",
        "    #그레이디언트 규제\r\n",
        "    w1_grad += (self.l1 * np.sign(self.w1) + self.l2 * self.w1) / m\r\n",
        "    w2_grad += (self.l1 * np.sign(self.w2) + self.l2 * self.w2) / m\r\n",
        "    #은닉층 가중치 절편 업데이트\r\n",
        "    self.w1 -= self.lr * w1_grad\r\n",
        "    self.b1 -= self.lr * b1_grad\r\n",
        "    #출력층 가중치 절편 업데이트\r\n",
        "    self.w2 -= self.lr * w2_grad\r\n",
        "    self.b2 -= self.lr * b2_grad\r\n",
        "\r\n",
        "    return a\r\n",
        "  \r\n",
        "  def predict(self, x):\r\n",
        "    z = self.forpass(x) #정방향 계산을 수행\r\n",
        "    return np.argmax(z, axis=1)  #가장 큰 값의 인덱스를 반환\r\n",
        "\r\n",
        "  def score(self, x, y):\r\n",
        "    #예측과 타깃 열 벡터를 비교하여 True의 비율을 반환\r\n",
        "    return np.mean(self.predict(x) == np.argmax(y, axis=1))\r\n",
        "\r\n",
        "  def update_val_loss(self, x_val, y_val):\r\n",
        "    z = self.forpass(x_val)   #정방향 계산\r\n",
        "    a = self.softmax(z)  #활성화 함수\r\n",
        "    a = np.clip(a, 1e-10,1-1e-10) #클리핑\r\n",
        "    val_loss = np.sum(-y_val*np.log(a))\r\n",
        "    self.val_losses.append((val_loss + self.reg_loss()) / len(y_val)) #로그 손실, 규제 손실 더하여 기록"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1G3n2hvSHMTP"
      },
      "source": [
        "class ConvolutionNetwork(MultiClassNetwork):\r\n",
        "\r\n",
        "  def __init__(self, n_kernels=10, units=10, batch_size=32, learning_rate=0.1):\r\n",
        "    self.n_kernels = n_kernels  #합성곱 커널 개수\r\n",
        "    self.kernel_size = 3  #커널 크기\r\n",
        "    self.optimizer = None #옵티마이저\r\n",
        "    self.conv_w = None  #합성곱층의 가중치\r\n",
        "    self.conv_b = None #합성곱층의 절편\r\n",
        "    self.units = units  #은닉층 뉴런 개수\r\n",
        "    self.batch_size = batch_size  #배치 크기\r\n",
        "    self.w1 = None  #은닉층 가중치\r\n",
        "    self.b1 = None  #은닉층 절편\r\n",
        "    self.w2 = None  #출력층 가중치\r\n",
        "    self.b2 = None  #출력층 절편\r\n",
        "    self.a1 = None  #은닉층 활성화 출력\r\n",
        "    self.losses = []  #훈련 손실\r\n",
        "    self.val_losses = []  #검승 손실\r\n",
        "    self.lr = learning_rate #학습률\r\n",
        "\r\n",
        "  def forpass(self, x):\r\n",
        "    c_out = tf.nn.conv2d(x, self.conv_w, strides=1, padding='SAME') + self.conv_b\r\n",
        "    r_out = tf.nn.relu(c_out)\r\n",
        "    #2 x 2 최대 풀링 적용\r\n",
        "    p_out = tf.nn.max_pool2d(r_out, ksize=2, strides=2, padding='VALID')\r\n",
        "    #첫 밴째 배치 차원 제외하고 일렬로\r\n",
        "    f_out = tf.reshape(p_out, [x.shape[0], -1])\r\n",
        "    z1 = tf.matmul(f_out, self.w1) + self.b1\r\n",
        "    a1 = tf.nn.relu(z1)\r\n",
        "    z2 = tf.matmul(a1, self.w2) + self.b2\r\n",
        "    return z2\r\n",
        "\r\n",
        "  def init_weights(self, input_shape, n_classes):\r\n",
        "    g = tf.initializers.glorot_uniform()\r\n",
        "    self.conv_w = tf.Variable(g((3, 3, 1, self.n_kernels)))\r\n",
        "    self.conv_b = tf.Variable(np.zeros(self.n_kernels), dtype=float)\r\n",
        "    n_features = 14 * 14 * self.n_kernels\r\n",
        "    self.w1 = tf.Variable(g((n_features, self.units)))  #특성 개수, 은닉층의 크기\r\n",
        "    self.b1 = tf.Variable(np.zeros(self.units), dtype=float)  #은닉층 크기\r\n",
        "    self.w2 = tf.Variable(g((self.units, n_classes))) #(은닉층 크기, 클래스 개수)\r\n",
        "    self.b2 = tf.Variable(np.zeros(n_classes), dtype=float) #클래스 개수\r\n",
        "\r\n",
        "  def training(self, x, y):\r\n",
        "    m = len(x)\r\n",
        "    with tf.GradientTape() as tape:\r\n",
        "      z = self.forpass(x) #정방향 계산\r\n",
        "      loss = tf.nn.softmax_cross_entropy_with_logits(y, z)\r\n",
        "      loss = tf.reduce_mean(loss)\r\n",
        "    weights_list = [self.conv_w, self.conv_b, self.w1, self.b1, self.w2, self.b2]\r\n",
        "    #가중치 그레이디언트 계산\r\n",
        "    grads = tape.gradient(loss, weights_list)\r\n",
        "    #가중치 업데이트\r\n",
        "    self.optimizer.apply_gradients(zip(grads, weights_list))\r\n",
        "\r\n",
        "\r\n",
        "  def fit(self, x, y, epochs=100, x_val=None, y_val=None):\r\n",
        "    self.init_weights(x.shape, y.shape[1])  #은닉층과 출력층의 가중치 초기화\r\n",
        "    self.optimizer = tf.optimizers.SGD(learning_rate=self.lr)\r\n",
        "\r\n",
        "    for i in range(epochs):\r\n",
        "      print('에포크', i, end=' ')\r\n",
        "      batch_losses = []\r\n",
        "      for x_batch, y_batch in self.gen_batch(x, y):\r\n",
        "        print('.', end=' ')\r\n",
        "        self.training(x_batch, y_batch)\r\n",
        "        batch_losses.append(self.get_loss(x_batch, y_batch))\r\n",
        "      print()\r\n",
        "      #배치 손실 평균 내어 훈련 손실값으로 지정\r\n",
        "      self.losses.append(np.mean(batch_losses))\r\n",
        "      #검증 세트에 대한 손실 계산\r\n",
        "      self.val_losses.append(self.get_loss(x_val, y_val))\r\n",
        "\r\n",
        "\r\n",
        "  def gen_batch(self, x, y):\r\n",
        "    bins = len(x) // self.batch_size  #미니배치 횟수\r\n",
        "    indexes = np.random.permutation(np.arange(len(x)))\r\n",
        "    x = x[indexes]\r\n",
        "    y = y[indexes]\r\n",
        "    for i in range(bins):\r\n",
        "      start = self.batch_size * i\r\n",
        "      end = self.batch_size * (i + 1)\r\n",
        "      yield x[start:end], y[start:end]\r\n",
        "\r\n",
        "\r\n",
        "  def get_loss(self, x, y):\r\n",
        "    z = self.forpass(x)\r\n",
        "    #손실 계산\r\n",
        "    loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(y, z))\r\n",
        "    return loss.numpy()  "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7M3MyaX5UUmF",
        "outputId": "0acc5790-105a-4ae0-d042-7da4d2ff90bb"
      },
      "source": [
        "!pip install tensorflow_gpu==2.0.0"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_gpu==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.0) (0.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.0) (1.32.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.0) (0.36.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.0) (3.3.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.0) (0.2.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.0) (1.1.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.0) (1.12.1)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.0) (2.0.1)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.0) (2.0.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.0) (1.15.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.0) (1.0.8)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.0) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.0) (3.12.4)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.0) (1.19.4)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_gpu==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (1.17.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (51.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (1.0.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (0.4.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (2.23.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow_gpu==2.0.0) (2.10.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (4.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (4.6)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (3.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (0.4.8)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow_gpu==2.0.0) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "zeuJcT6OUiJ6",
        "outputId": "ff8afebb-03e7-4ab2-a14d-b3e73bc860a3"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "\r\n",
        "tf.__version__"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.0.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rDzGEyUUyTF",
        "outputId": "9df2bdc4-1ef8-4200-eb16-696d8047037c"
      },
      "source": [
        "(x_train_all, y_train_all), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\r\n",
        "\r\n",
        "print(x_train_all.shape, y_train_all.shape)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 28, 28) (60000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "ThAoqGseVja_",
        "outputId": "96bf37db-6347-4024-f371-a43641758b6b"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "plt.imshow(x_train_all[0], cmap='gray')\r\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoLeSvoPV11F",
        "outputId": "8a1b1778-30a9-44d3-9b7e-0e544c9a2516"
      },
      "source": [
        "print(y_train_all[:10])\r\n",
        "\r\n",
        "class_names = ['티셔츠/윗도리', '바지', '스웨터', '드레스', '코트', '샌들', '셔츠', '스니커즈', '가방', '앵클부츠']\r\n",
        "\r\n",
        "print(class_names[y_train_all[0]])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 0 0 3 0 2 7 2 5 5]\n",
            "앵클부츠\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7sQLZROWlHL",
        "outputId": "00b95980-c3a5-4a7c-9eb2-8615f4bcedaf"
      },
      "source": [
        "np.bincount(y_train_all)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNFnAloSW7zW",
        "outputId": "83fad8a9-c711-4ae3-eb5b-9f332ca77a87"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train_all, y_train_all, stratify=y_train_all, test_size=0.2, random_state=42)\r\n",
        "print(np.bincount(y_train))\r\n",
        "print(np.bincount(y_val))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[4800 4800 4800 4800 4800 4800 4800 4800 4800 4800]\n",
            "[1200 1200 1200 1200 1200 1200 1200 1200 1200 1200]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ib4p5hUOXpsj"
      },
      "source": [
        "x_train = x_train / 255\r\n",
        "x_val = x_val /255"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q1Ec26BQX8vg",
        "outputId": "dc106bdf-1b28-46fb-c20c-0f3ee1265af3"
      },
      "source": [
        "x_train = x_train.reshape(-1, 28, 28, 1)\r\n",
        "x_val = x_val.reshape(-1, 28, 28, 1)\r\n",
        "\r\n",
        "print(x_train.shape, x_val.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(48000, 28, 28, 1) (12000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sM1CKqARYx1p",
        "outputId": "064f3e99-418e-4c2d-a74c-661a7edc0173"
      },
      "source": [
        "y_train_encoded = tf.keras.utils.to_categorical(y_train)\r\n",
        "y_val_encoded = tf.keras.utils.to_categorical(y_val)\r\n",
        "\r\n",
        "print(y_train[0], y_train_encoded[0])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "6 [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ntzq9k0ddG3K",
        "outputId": "b2d3cc4a-bba3-495d-827e-26474f7704fa"
      },
      "source": [
        "cn = ConvolutionNetwork(n_kernels=10, units=100, batch_size=128, learning_rate=0.01)\r\n",
        "cn.fit(x_train, y_train_encoded, x_val=x_val, y_val=y_val_encoded, epochs=20)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "에포크 0 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
            "에포크 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
            "에포크 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
            "에포크 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
            "에포크 4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
            "에포크 5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
            "에포크 6 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
            "에포크 7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
            "에포크 8 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
            "에포크 9 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
            "에포크 10 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
            "에포크 11 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
            "에포크 12 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
            "에포크 13 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
            "에포크 14 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
            "에포크 15 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
            "에포크 16 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
            "에포크 17 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
            "에포크 18 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
            "에포크 19 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "jLdOq-SUbCER",
        "outputId": "629ec869-ec1b-4e81-a1cc-af25d9049199"
      },
      "source": [
        "plt.plot(cn.losses)\r\n",
        "plt.plot(cn.val_losses)\r\n",
        "plt.ylabel('loss')\r\n",
        "plt.xlabel('iteration')\r\n",
        "plt.legend(['train_loss', 'val_loss'])\r\n",
        "plt.show()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K35g9f3nbMhz",
        "outputId": "5db47665-5d59-4428-d8d3-e8262ffee747"
      },
      "source": [
        "cn.score(x_val, y_val_encoded)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8795833333333334"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    }
  ]
}